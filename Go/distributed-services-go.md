在建立JSON/HTTP Go服务器时，每个处理程序由三个步骤组成。

1. 将请求的JSON主体解压缩为一个结构。

2. 用请求运行该端点的逻辑，以获得一个结果。

3. 将结果打包并写入响应中。

Protobuf lets you define how you want your data structured, compile your protobuf into code in potentially many languages, and then read and write your structured data to and from different data streams.



## Chapter 3 Write a Log Package

在这本书中，我们要构建一个分布式服务，以学习如何用Go创建分布式服务。但是在这一章中，构建一个日志是如何帮助我们实现这一目标的呢？我相信在构建分布式服务时，日志是你的工具包中最重要的工具。日志--有时也被称为写前日志(write-ahead log)、事务日志或提交日志--是存储引擎、消息队列、版本控制以及复制和共识算法的核心。当你构建分布式服务时，你会遇到一些问题，你可以用日志来解决。通过自己建立一个日志，你将学会如何。

- 使用日志解决问题，并发现它们如何使困难的问题变得更容易。

- 改变现有的基于日志的系统以适应你的需要，并建立你自己的基于日志的系统。

- 在构建存储引擎时有效地写入和读取数据。

- 防止因系统故障造成的数据丢失。

- 对数据进行编码，以便将其持久地保存在磁盘上，或者建立你自己的协议，并在应用程序之间发送数据。

数据库开发人员也将WAL用于复制。他们不把日志写到磁盘上，而是通过网络把日志写到其副本上。复制体将这些变化应用到他们自己的数据副本中，最终他们都会达到相同的状态。Raft是一种共识算法，使用同样的想法让分布式服务在整个集群的状态上达成一致。Raft集群中的每个节点都运行一个以日志为输入的状态机。Raft集群的领导者将变化附加到其跟随者的日志中。由于状态机使用日志作为输入，而且日志的记录顺序相同，所以所有的服务最终的状态都是一样的。



当你把一条记录追加到日志中时，**日志会给该记录分配一个唯一的、连续的偏移数，这个偏移数就像该记录的ID**。日志就像一张表，它总是按时间对记录进行排序，并按其偏移量和创建时间对每条记录进行索引。

为了实现日志系统，我们必须处理没有无限空间的磁盘的问题，这意味着我们不能永远追加到同一个文件中。所以我们把日志分成**一个段的列表**。当日志长得太大的时候，我们就通过删除那些我们已经处理过或存档过的旧片段来释放磁盘空间。这种对旧段的清理可以在后台进程中运行，而我们的服务仍然可以向活动的（最新的）段生产，并从其他段消费，在goroutines访问相同的数据时没有冲突，或者至少减少一些冲突。

在段的列表中总有一个特殊的段，那就是活动段。我们称它为**活动段**，因为它是我们唯一主动写入的段。当我们填满活动段时，我们创建一个新的段，并将其作为活动段。

每个段包括一个存储文件和一个索引文件。该段的存储文件是我们存储记录数据的地方；我们不断地将记录追加到这个文件。该段的索引文件是我们为存储文件中的每条记录编制索引的地方。**索引文件加快了读取速度，因为它将记录的偏移量映射到存储文件中的位置**。读取一条记录的偏移量是一个两步的过程：**首先你从索引文件中获得该记录的条目，它告诉你该记录在存储文件中的位置，然后你在存储文件中的那个位置读取记录。**由于索引文件只需要两个小字段--偏移量和记录的存储位置--索引文件要比存储所有记录数据的存储文件小得多。

我们将自下而上建立我们的日志，从存储和索引文件开始，然后是段，最后是日志。这样，我们就可以在构建每一块的时候编写和运行测试。由于日志这个词至少可以指三种不同的东西--记录、存储记录的文件和将段连接在一起的抽象数据类型--为了使事情不那么混乱，在本章中，我将始终使用以下术语来表示这些东西。

**Record** - the data stored in your log

**Store** - the file we store records in

**Index** - the file we store index entires in

Segment - the abstraction that ties a store and an index together

Log - the abstraction that ties all the segments together

### store

`./internal/log/store.go`

存储结构是一个简单的文件包装，有两个API来追加和读取文件中的字节。`newStore(*os.File)`函数为给定的文件创建一个存储。该函数调用`os.Stat(name string)`来获取文件的当前大小，以防我们从一个已有数据的文件中重新创建存储，例如，如果我们的服务重新启动，就会发生这种情况。

索引条目包含两个字段：记录的偏移量和他在存储文件中的位置。将偏移量存储为`uint32`，将位置存储为`uint64`，因此它们分别占用了，4字节和8字节的空间。我们使用`endWidth`来直接跳到一个条目的位置，因为在条目中的位置是`offset * endWidth`



当我们启动我们的服务时，服务需要知道在追加到日志的下一条记录上要设置的**偏移量**。服务通过查看索引的最后一条来了解下一条记录的**偏移量**，这是一个读取文件最后12字节的简单过程。

然而，当我们增加文件以便对它们进行内存映射时，我们把这个过程弄乱了。(我们现在调整它们的大小的原因是，一旦它们被内存映射，我们就不能再调整它们的大小，所以要么现在，要么永远不。）

我们通过在文件的末尾添加空的空间来增加文件的大小，所以最后一条不再是文件的末尾--相反，在这条和文件末尾之间有一些未知的空间。这个空间使服务无法正常重启。这就是为什么我们通过截断索引文件来关闭服务，以去除空的空间，并再次将最后一个条目放在文件的末尾。这种优雅的关闭使服务返回到一个可以正确有效地重新启动的状态。



### index

`./internal/log/index.go`

我们在整个索引中使用`*Width`常量，所以就像商店的变量和常量一样，我们把常量放在文件的顶部，使它们容易被找到。`*Width`常量定义了组成每个索引条目的字节数。

我们的索引条目包含两个字段：**记录的偏移量**和它在**存储文件中的位置**。我们将偏移量存储为uint32s，将位置存储为uint64s，因此它们分别占用了4和8个字节的空间。我们使用`entWidth`来直接跳到一个条目的位置，因为文件中的位置是`offset * entWidth`。

`index` 定义索引文件，它包括一个持久化的文件和一个内存映射的文件。

`size`表明索引文件的大小，以及在哪里写入下一个索引条目

`newIndex(*os.File)`为给定文件创建一个索引。我们创建索引并保存文件的当前大小，这样我们就可以在添加索引项时跟踪索引文件中的数据量。**在对文件进行内存映射之前，我们将文件增长到最大的索引大小，然后将创建的索引返回给调用者。**

:red_circle: `Read(int64)`接收一个**偏移量**并返回相关记录在存储区的位置。给定的偏移量是**相对于段的基本偏移量**而言的；0总是索引的第一个条目的偏移量，1是第二个条目，以此类推。**我们使用相对偏移量，通过将偏移量存储为uint32s来减少索引的大小**。如果我们使用绝对偏移，我们将不得不把偏移量存储为uint64s，并且每个条目需要多四个字节。四个字节听起来并不多，直到你把它乘以人们经常使用分布式日志的记录数量，对于像LinkedIn这样的公司，每天有数万亿条记录。即使是相对较小的公司，每天也会有数十亿条记录。



### segment

该段包装了索引和存储类型以协调两者之间的操作。例如，当日志将一条记录追加到活动段时，该段需要将数据写入其存储空间，并在索引中添加一个新条目。同样，对于读取来说，该段需要从索引中查找条目，然后从存储中获取数据。



segment需要调用它的存储和索引文件，所以我们在前两个字段中保留指向这些文件的指针。我们需要`nextOffset`(下一个偏移量）和`baseOffset`基本偏移量，以知道在什么偏移量下追加新的记录，并计算出索引项的相对偏移量。**我们把配置放在段上，这样我们就可以把存储文件和索引的大小与配置的限制进行比较，这让我们知道段什么时候已经达到极限。**





当它需要添加一个新的段时，例如当当前活动段达到其最大尺寸时，日志会调用`newSegment()`。我们打开存储文件和索引文件，并将`os.O_CREATE`文件模式标志作为参数传递给os.OpenFile()，以在文件还不存在时创建它们。当我们创建存储文件时，我们传递`os.O_APPEND`标志，使操作系统在写入时追加到该文件。然后我们用这些文件创建我们的索引和存储。最后，我们设置段的下一个偏移量，为下一个追加的记录做准备。



`Append()`将记录写入段中，并返回新添加的记录的**偏移量**。日志将**偏移量**返回到API响应中。该段在两步过程中追加一条记录：它将数据追加到存储区，然后添加一个索引条目。由于索引偏移量是相对于基本偏移量的，我们用段的下一个偏移量减去它的基本偏移量（都是绝对偏移量），得到该段中的条目的相对偏移量。然后我们增加下一个偏移量，为将来的追加调用做准备。



`Read(off uint64)` 返回给定偏移量的记录。与写类似，要读一条记录，段必须首先将`绝对索引`转换为`相对偏移量`，并获得相关的索引条目。一旦有了索引条目，该段就可以直接进入该记录在存储区的位置并读取适当的数据量。



nearestMultiple(j uint64, k uint64)返回j中k的最近和较小的倍数，例如nearestMultiple(9, 4) == 8。我们采取较小的倍数，以确保我们保持在用户的磁盘容量之下。



### Code the log

`Truncate(lower uint64) `删除所有最高偏移量低于最低偏移量的段。因为我们没有无限空间的磁盘，我们会定期调用`Truncate()`来删除那些我们（希望）已经处理过并且不再需要的旧段。

Reader()返回一个io.Reader来读取整个日志。当我们实现坐标共识并需要支持快照和恢复日志时，我们将需要这种能力。Reader()使用io.MultiReader()调用来串联段的存储。segment stores被originReader类型所包裹，有两个原因。第一个原因是为了满足io.Reader接口，所以我们可以把它传递给io.MultiReader()调用。第二个原因是为了确保我们从存储的原点开始读取，并读取其整个文件。



## Chapter 4 Serve Requests with gRPC

与在单台计算机上运行的程序相比，网络化服务有三大优势。

- 你可以在多台计算机上运行它们，以获得可用性和可扩展性。

- 它们允许多人与同一数据互动。

- 它们提供易于人们使用的界面。

在一些情况下，你会想要编写服务来获得这些优势，包括为你的前端提供公共API，建立内部基础设施工具，以及制作一个服务来建立你自己的业务（人们很少为使用图书馆付费）。

在这一章中，我们将在我们的库的基础上，制作一个允许多人与同一数据交互并在多台计算机上运行的服务。

### What Is gRPC?

过去我在构建分布式服务时，有两个常见的问题让我抓狂，那就是保持兼容性和保持客户端与服务器之间的性能。

我想确保客户端和服务器始终是兼容的--客户端发送的请求服务器能理解，反之，服务器的响应也能理解。当我对服务器进行突破性的修改时，我想确保旧的客户端能够继续工作，我通过版本化的API来实现这一目的。

为了保持良好的性能，你的主要任务是优化你的数据库查询和优化你用来实现业务逻辑的算法。一旦你优化了这些，性能往往会归结为你的服务解开请求和处理响应的速度，以及减少客户和服务器每次通信的开销--比如使用一个持久的连接，而不是为每个请求建立一个新的连接。

因此，当Google发布gRPC--一个开源的、高性能的RPC（远程过程调用）框架时，我很高兴。gRPC对解决构建分布式系统时的这些问题有很大帮助，我想你会发现它简化了你的工作。gRPC如何帮助你构建服务？

### Goals When building a service

以下是你在建立网络化服务时要达到的最重要的目标，以及一些关于gRPC如何帮助你实现这些目标的信息：

Simplicity

网络通信是技术性的和复杂的。在建立我们的服务时，我们希望把注意力放在它所解决的问题上，而不是请求-响应序列化等技术细节上。你希望与抽象出这些细节的API一起工作。然而，当你需要在较低的抽象层次上工作时，你需要这些层次能够被访问。

Maintainability

Security

Ease of use

### Define a gRPC Service

`gRPC`服务本质上是一组相关的RPC端点--具体如何关联由你决定。一个常见的例子是`RESTful`分组，其中的关系是各端点对同一资源进行操作，但分组可以比这更松散。一般来说，它只是解决某些问题所需的一组端点。在我们的案例中，目标是使人们能够写入和读出他们的日志。

创建一个gRPC服务需要在protobuf中定义它，然后将你的协议缓冲区编译成由客户和服务器存根组成的代码，然后实现它。为了开始，打开`log.proto`，即我们定义Record消息的文件，并在这些消息上方添加以下服务定义。

service关键字表示这是一个供编译器生成的服务，每一行RPC都是该服务的一个端点，指定端点接受的请求和响应类型。请求和响应是编译器将其转化为Go结构的消息，就像我们在上一章看到的那些。

ConsumeStream - 一个服务器端的流式RPC，客户端向服务器发送一个请求，并得到一个流来读取一连串的消息。

ProduceStream - 一个双向的流式RPC，客户端和服务器都使用一个读写流发送一串消息。这两个流是独立运行的，所以客户端和服务器可以按照他们喜欢的顺序进行读写。例如，服务器可以等待收到客户的所有请求后再发回它的响应。如果你的服务器需要分批处理请求，或者在多个请求中聚合一个响应，你就会这样安排你的调用。另外，服务器也可以对每个请求同步发送响应。如果每个请求都需要自己相应的响应，你可以这样安排你的调用。

请求包括要产生到日志的**记录**，而响应则送回记录的**偏移量**，这基本上是记录的标识符。与消费类似：用户指定他们想消费的日志的偏移量，而服务器则用指定的记录回馈。

为了用我们的日志服务定义生成客户端和服务器端的代码，我们需要告诉protobuf编译器使用gRPC插件。



`ProduceStream(api.Log_ProduceStreamServer)`实现了一个双向的流式RPC，因此客户端可以将数据流到服务器的日志中，服务器可以告诉客户端每个请求是否成功。`ConsumeStream(*api.ConsumeRequest, api.Log_ConsumeStreamServer)`实现了一个服务器端的流式RPC，因此客户端可以告诉服务器在日志中的哪个位置读取记录，然后服务器会流式处理后面的每一条记录--甚至是还没有在日志中的记录 当服务器到达日志的末尾时，服务器将等待，直到有人将记录添加到日志中，然后继续向客户端传输记录。

有了我们的自定义错误，当客户端试图使用一个在可用范围之外的偏移量时，日志会返回一个带有大量有用信息的错误：一个本地化的消息、一个状态代码和一个错误信息。因为我们的错误是一个结构类型，我们可以对Read(offset uint64)方法返回的错误进行类型转换，以了解发生了什么。我们已经在我们的`ConsumeStream(*api.ConsumeRequest, api.Log_ConsumeStreamServer)`方法中使用了这个功能，以知道服务器是否已经读到了日志的末尾，只需要等待有人向客户端产生另一条记录。



### Dependency Inversion with Interfaces

我们的服务器依赖于一个日志抽象。例如，当在生产环境中运行时--我们需要持久化我们用户的数据--服务将依赖于我们的库。但当在测试环境中运行时，我们不需要持久化我们的测试数据，我们可以使用一个天真的、内存中的日志。内存日志对测试也有好处，因为它可以使测试运行得更快。

从这些例子中你可以看到，如果我们的服务不与特定的日志实现相联系，那将是最好的。相反，我们希望根据我们当时的需要传递一个日志实现。我们可以通过让我们的服务依赖于一个日志接口而不是一个具体的类型来实现这个目标。这样一来，服务可以使用任何满足日志接口的日志实现。



## Chapter 5 Secure Your Services



### Secure Services In Three Steps

分布式服务的安全可分为三个步骤：

1. 对传输的数据进行加密，以防止中间人攻击
2. 认证（Authentication），以识别客户
3. 授权（Auhthorization），来确定被识别的客户的权限。

在这个握手过程中，客户和服务器。

1. 指定他们将使用哪个版本的TLS。

2. 决定他们将使用哪些密码套件（一组加密算法）。

3. 通过服务器的私钥和证书机构的数字签名来认证服务器的身份；以及

4. 在握手完成后为对称加密生成会话密钥。

Authentication

一旦你用TLS保证了客户端和服务器之间的通信，安全服务的下一步就是认证。认证是识别客户是谁的过程（TLS已经处理了对服务器的认证）。例如，每当你发布一条推文，Twitter需要验证试图将推文发布到你的账户的人真的是你。

大多数网络服务使用TLS进行单向认证，只对服务器进行认证。客户端的认证是留给应用程序来解决的，通常是通过用户名-密码凭证和令牌的某种组合。TLS相互认证，通常也被称为双向认证，其中服务器和客户端都验证对方的通信，更常用于机器对机器的通信，如分布式系统! 在这种设置中，服务器和客户端都使用一个证书来证明他们的身份。

由于相互`TLS`认证非常有效，相对简单，而且被广泛采用（无论是从使用它的人数还是从支持它的技术数量来看），许多公司用它来保证他们内部分布式服务之间的通信。因为有这么多人使用相互TLS认证，所以新的服务（如我们的）必须支持它。所以我们将在我们的服务中建立相互TLS认证。



Authorization

当你有一个具有共享访问权和不同级别所有权的资源时，区分认证和授权是必要的。以我们的日志服务为例，Alice可能是所有者，对日志的内容有读和写的权限，而Bob可能被允许读内容，但不能写。在这种情况下，你需要具有细粒度访问控制的授权。

在我们的服务中，我们将建立基于访问控制列表的授权，以控制客户是否被允许读取或写入（或两者）日志。



CFSSL有两个我们需要的工具。

- `cfssl`用于签署、验证和捆绑TLS证书，并将结果输出为JSON格式。

- `cfssljson`将JSON格式的输出结果分割成独立的密钥、证书、CSR和捆绑文件。

`ca-csr.json`

• C—country

• L—locality or municipality (such as city)

• ST—state or province

• O—organization

• OU—organizational unit (such as the department responsible for owning the key)

`./internal/config/tls.go`

我们将使用证书和密钥文件来构建`*tls.Configs`，所以让我们为其添加一个辅助函数和结构。在配置目录中，创建一个`tls.go`文件，以这个代码开始。

我们的测试使用不同的`tls.Config`配置，SetupTLSConfig()允许我们通过一个函数调用来获得每种类型的*tls.Config。这些是不同的配置。

- 客户端`tls.Config`被设置为通过设置`*tls.Config`的RootCAs来验证服务器和客户端的证书。

- 客户端`*tls.Config`被设置为验证服务器的证书，并允许服务器通过设置其`RootCAs`和其证书来验证客户端的证书。

- 服务器`*tls.Config`被设置为验证客户的证书，并允许客户通过设置其`ClientCAs`、`Certificate`和`ClientAuth`模式为`tls.RequireAndVerifyCert`来验证服务器的证书。

`TLSConfig`定义了`SetupTLSConfig()`用来决定返回何种类型的`*tls.Config`的参数。

回到我们的测试。让我们测试一下，客户端使用我们的CA来验证服务器的证书。如果服务器的证书来自不同的机构，客户端就不会信任服务器，也就不会建立连接。

`internal/server/server.go`

在这段代码中，我们配置客户端的TLS证书，将我们的`CA`作为客户端的根`CA`（它将用来验证服务器的CA）。然后我们告诉客户端使用这些证书进行连接。

接下来，我们需要将我们的服务器与它的证书连接起来，使它能够处理TLS连接。在前面的片段下面添加以下代码:

在这段代码中，我们正在解析服务器的证书和密钥，然后用它来配置服务器的`TLS`凭证。然后我们将这些证书作为`gRPC`服务器选项传递给我们的`NewGRPCServer()`函数，这样它就可以用该选项创建我们的`gRPC`服务器。在这种情况下，我们要设置服务器连接的凭证，但是还有很多其他的服务器选项，比如配置连接超时、保持活力策略等等。

最后，我们需要更新`server.go`中的`NewGRPCServer()`函数，以接收给定的`gRPC`服务器选项并使用这些选项创建服务器。把`NewGRPCServer()`函数改成这样。
